##  面试开场白



## 5W原则

- 名字 + 东华理工大学（不提地名） + 专业软件工程

- 为什么要走前端方向 -- 学校中有软件 社团 跟随学长的智能前端方向 
- 学前端的方式：学长  + 自学 + 通读 《你不知道的JAVASCRIPT》

- 过去的一年中 深度学习了 JAVASCRIPT ES6 CSS REACT HTML5等 
- REACT 为主 了解 VUE 

- 喜欢在掘金社区 发表一些高质量文章 成就

- 最近对AI非常感兴趣 对智能前端这一块非常感兴趣 项目中使用了一些

- 拥抱AI编程
- 相信自己能够胜任岗位中的要求 期待未来 非常荣幸000能够得到机会 未来会投入到工作与学习


你好，我是姚康，来自东华理工大学，专业是软件工程，在大学期间，受到计算机协会的学长启示，开始了前端学习，通过自学掘金的技术文章，通读《你不知道的Javascript》等书籍 ，掌握了许多前端知识点，其中包括但不限于 JS的es6，闭包，原型链，词法作用域等知识，CSS的BEM,BFC,flex布局,等 HTML5 知识，我也在掘金社区输出了70多篇高质量文章，我精通React， 最近对AI非常感兴趣，体验过一些AI社区：月之暗面，KImi，transformer，也动手开发过一些扣子的工作流，相信我在未来能够胜任岗位中的要求，跟团队进行协同合作




面试官您好，我叫姚康 来自东华理工大学 就读于软件工程专业 首先我想来介绍下为什么我要学习前端和我的学习方法：首先，学习前端的经历起源于我在大学期间计算机社团的一段经历，认识了几位优秀的学长 在他们的启示下 我接触到了智能前端方向 自身对该方向也十分感兴趣，所以我就正式开启了我的前端学习之路 在学习方法这块，低年级时我是通过学习一些b站等平台的视频来学习基础知识，后续我是通过阅读书籍，观看掘金平台的技术文章来深度钻研前端知识，其中我通读了一本叫做《你不知道的Javascript》的著作，也阅读了大量的掘金社区文章 自己同样作为一名创作者 写了80余篇原创文章。上述就是我的一些学习路线和学习方法。接下来我想讲讲我在对AI的了解，然后最近一年我个人对ai这方面十分感兴趣，我时刻关注着大量的ai平台，例如扣子，transformer，魔塔，火山引擎等，也自己体验了许多功能，其中我使用扣子平台开发了一些智能体和工作流，体验过魔塔社区的nlp情感分析任务等 同时也在关注着新兴协议和技术，例如FUNCTION CALL RAG MCP等等,然后在平常的编程开发中，我会使用ai辅助编辑器为我的开发进行赋能，例如trae，cursor辅助开发，蓝湖，Google Stitch辅助设计。自己对ai这一方面也十分看好，我个人认为未来的开发是离不开ai的。最后感谢面试官能够给我提供这一次宝贵的面试，我相信未来能够胜任贵公司的业务开发和积极融入到贵公司的团队合作，以上是我的自我介绍，谢谢


开场

 ai包袱

介绍项目亮点：（注重实战能力）

- 瀑布流：InterceptionObserver
- jwt
- mock 
- 骨架屏（已做）
- 流式输出
- deepseek调用
- 防抖节流--搜索建议
- 闭包陷阱
- 自定义hooks

next项目

- 单例模式
- Promise.all
- Map缓存
- 



项目：

端模型 -- 应用场景：一些是实时的，智能驾驶等场景



流程

1.个人介绍

2.甩3-4个包袱

css

项目难点/亮点 



**常考题**：
- 性能优化：路由懒加载、无限滚动瀑布流、图片懒加载、webworker、一些组件的合理使用（useMemo）、
- useEffect 副作用阐述
- useContext的用法
- useReducer
- seo
- 
- 次要：为什么要放在头部的Hooks函数

到时候问下喻导字节面试是否需要在面试前修改简历
问下是否需要 准备一些话术 说第二个项目的情况
项目提前准备能够运行的环境

后续安排
- 写文章总结项目中的性能优化
- 写文章总结项目中的亮点
- 写文章总结项目中的难点
- 手写题


具体一些时间安排：
周末弄手写题和总结项目
手写题：常见的过一遍，通过写文章
总结项目：
两个项目一起总结 
难点和亮点

再次总结胡总的面试经验

大体逻辑：
学习并实践了一个段模型的项目
- **项目亮点**
- 我的这个项目的核心亮点就是将来自Huggingface社区的transfomer模型库里的系列tts模型下载到浏览器本地，项目可以直接通过执行已下载的本地模型来实现实现的文本转语音的效果，这种方式区别于传统的远程api调用大模型服务器返回的结果，在时效性和隐私性等得到了进一步的保障。
- **具体实现**
- 具体来说，当用户输入需要转语音的内容并选择音色后，按下生成的button，此时咱们通过webworker开启另一个下载线程，在这个线程内，首先从模型库中引入自动分词器AutoTokenizer、文本转语音的核心模型：SpeechT5ForTextToSpeech和语音合成的模型SpeechT5HifiGan，首先，AutoTokenizer是帮我们将输入的即将需要转换成语音的text转换为大模型更利于理解的token，然后是文本转语音的核心模型SpeechT5ForTextToSpeech，它能够根据用户输入的text和用户选择的音色 得到512维的语音特征向量，为后续的音频生成提供必要的语言特征数据，最后是SpeechT5HifiGan，它主要负责将刚刚得到的语言特征向量转变为实际d 音频波形数据，使用HifiGan技术生成高质量的音频输出，最终经过这三个模型的共同协作，我们能够得到声波文件waveform，将waveform经过Blob转换，返回给主线程App.jsx，再经过URL.createObjectURL()得到可播放的文件，使得用户可以点击后立即听到转变后的语音。
**涉及到的性能优化和用户体验**
- 单例模式：因为咱们对模型的下载是需要耗费很多时间的，所以为了避免重复下载，使用单例模式这种设计模式
- Promise.all，使用Promise.all 能够使得不同的模型下载同步进行
- 整个项目采用的是tailwindcss，能够有效地管理组件样式的
用户体验
- 实时传输加载条的进度数据，通过postMessage实时地向渲染的线程发送当前模型的下载进度，具体来说是通过一个数组来记录各个模型的下载进度，然后主线程可以根据接收到的数组进行渲染
- 初次之外，我们采用了大量的useState管理一些按钮等组件，
## 最终详谈
性能不是特别的好，因为这个技术还不算成熟，跟deepseek等成熟的模型相比，稳定性并没有保障，但是我相信未来，也许我们能够在这方面有所建树


## SmartTrip项目亮点/难点
随着国内旅游出行的需求近年来逐步上升，用户需要一款界面精美，功能丰富的旅游App，并且还能接入当前最火的AI功能，所以这款项目就应运而生了。
接下俩我将介绍下项目的几部分亮点和难点

首先咱们用户进入首页和进入到推荐页、关注页时可以实现一个类似于抖音、快手、小红书等应用软件的一个无限加载瀑布流的效果，我来介绍下它的大体实现流程，实现流程分为两方面：

难点
- 无限加载瀑布流 （图片懒加载 + fetch）
类似于抖音、快手、小红书的效果，我来介绍一下具体实现方案和核心流程：

一方面，实现了无限滚动：在页面底部放置一个 loader 元素作为触发点，使用IntersectionObserver这个浏览器检测最底部的Loader是否进入视口来实现，用户在下划的过程中，Loader进入了视口，此时会执行设定好的回调函数：使用fetchRecommands获取新数据并追加到现有数据中。
另一方面。实现了图片懒加载：对于未进入到视口的图片，默认使用占位图，同时会将真正的图片地址设置到data-src属性中，同样使用 IntersectionObserver 监听每张图片，只有当图片进入到视口时，才会触发Intersection Observer设置的回调函数： 根据将占位图换成实际的dataset-src的图片，这个过程会先创建一个图片元素进行一个预加载，倘若加载成功了，则直接进行替换，倘若加载失败了，则会将当前的src换成加载失败时的图片

大体的无限加载瀑布流我认为可以通过上面两种方式协同实现：其中还涉及到一些性能优化点：通过在useEffect里设置return在卸载阶段 将IntersectionObserver声明的实例给disconnect
还有在当前图片加载成功后，会 obs.unobserve(entry.target)取消对当前已加载图片的观察，在无限滚动的实现中：设置了loading防止重复请求，最后由于这个InterceptionObserver的这套模式在很多地方都会被用到，我使用了自定义HOOKS封装：在这个自定Hook中，需要传入加载更多的函数和loading，这个自定义hook函数最终返回了loader这个useRef声明的实例。

- 搜索建议
这是一个实时搜索建议功能，类似于百度、谷歌搜索框的下拉提示效果。当用户在搜索框中输入关键词时，系统会实时显示相关的搜索建议，帮助用户快速找到想要的内容。
用户输入"九江"时，下拉框会显示"九江庐山"、"九江本地游"等相关建议

搜索建议实现的大体流程：

首先我的搜索栏会作为子组件放在父组件搜索页面中，父组件搜索页面会给子组件搜索栏一个自定义事件HandleData作为props，在子子组件搜索栏中放一个受控组件输入框，当用户在子组件搜索栏中的输入框进行不断输入时，通过执行onChange里面的回调函数：执行防抖后的HandleData，设置为当用户停止输入0.3秒后，才会执行父组件的props里面的handleData,此时父组件的handleData会运行通过zustand中store的fetchSuggest进行获取搜索数据    ，此时可以通过MVVM模式将获取到的搜索建议给渲染到当前的页面中，最终用户就可以看到搜索建议。

大体流程是这样的，具体还涉及到许许多多的性能优化和用户体验，例如在用户输入时会提示一个清除按钮，用户可以通过点击清除按钮一键清空当前输入框里的内容，在fetchMore还没有拿到结果时，哦通过useState设置响应式状态isLoading管理显示正在转圈的动画，使用useMemo创建防抖函数，使得无需多次创建。

- jwt
使用jwt实现了用户登录，区别于传统的cookie/session 可以更加便捷和更加安全，使得能够减少crsf和xss攻击等，而且无需依赖服务器的sesssion
并且通过zustand配合loaclStorage全局管理的当前的登录状态，

亮点
- 接入deepseekLLM大模型
    接入了deepseekLLM的接口，设置了一段系统提示词：使得智能客服只能回答旅游相关的问题和该旅游平台相关的问题
    并且能够支持md文档格式的输出和支持流式输出的效果
    流式输出是如何实现的
    
    "在我们的智行云游项目中，我实现了一个AI客服的流式输出功能，主要是为了提升用户体验，让用户能够实时看到AI回复的过程，而不是等待完整回答后一次性显示。

整个流式输出的实现分为两个层次。首先是API层面，我们调用DeepSeek的流式API，在请求参数中设置stream为true来启用流式模式。当服务器返回response后，response.body实际上是一个ReadableStream对象，我通过getReader方法获取一个阅读器reader，然后用while循环不断调用reader.read方法来逐块读取数据。每次read会返回一个包含done和value的对象，done表示流是否结束，value是一个Uint8Array字节数组。

接下来是数据处理部分，我用TextDecoder将字节数组解码成文本字符串，因为SSE协议是基于行的，所以用split换行符来分割每一行。SSE格式的数据行都以'data:'开头，我提取出后面的JSON数据进行解析，从choices数组的delta.content字段中获取本次新增的文本片段，然后累积到fullContent中，并立即调用onStreamUpdate回调函数来通知UI层更新显示。

在UI层面，我用了三个关键状态来控制显示：isSending表示是否正在发送请求，isStreaming表示是否正在流式输出，streamingContent存储临时的流式内容。当开始发送时显示加载动画，一旦收到第一个文本片段就切换到流式输出状态，实时渲染streamingContent到界面上，同时用useEffect监听内容变化自动滚动到底部。等流式输出完成后，将完整消息添加到历史记录中，并重置所有状态。
这样实现的好处是用户能够实时看到AI的回复过程，提升了交互体验，同时通过合理的状态管理确保了界面的流畅性和错误处理的完整性。"


简洁版：
"首先，在API层面，调用DEEPSEEK的API接口，在请求参数中设置stream为true，使得后续的模式为SSE模式。DEEPSEEK服务器会持续不断地主动向客户端发送数据块，客户端可以利用decoder将接收到的字节数组进行一个转UTF-8解码和按行分割的操作，得到基于SSE格式的文本。然后通过split分隔每一行，配合while(true)循环持续不断地将得到的结果增加到fullContent中，同时调用回调函数onStreamUpdate将当前的fullContent发送到UI层进行渲染。"




回答：

- 概念/通用概念->本质是什么？
- 特点
- 应用场景/解决办法
- 缺点
- 我还想补充一点/未来展望： 
- 